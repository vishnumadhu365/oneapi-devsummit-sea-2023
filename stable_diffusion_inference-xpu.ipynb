{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b9e466e",
   "metadata": {},
   "source": [
    "<font size=\"5\"> **Stable Diffusion Inference on Intel® Data Center GPU Max 1100** </font> \n",
    "<br>\n",
    "This code sample will perform stable diffusion inference based on the text prompt using KerasCV implementation while using Intel® Extension for Tensorflow*. The following run cases are executed:<br>\n",
    "* FP32 (baseline) <br>\n",
    "* Advanced Auto Mixed Precision FP16 <br>\n",
    "\n",
    "<font size=\"5\">**Environment Setup**</font>  <br>\n",
    "Ensure the **itex_xpu kernel** is activated before running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0a9d25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['ITEX_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "#os.environ['ZE_AFFINITY_MASK'] = str(gpu_device)\n",
    "\n",
    "import time\n",
    "from keras_cv.models.stable_diffusion import StableDiffusion\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425fe3ef-804b-42e4-bee3-f2058330f7d7",
   "metadata": {},
   "source": [
    "<font size =\"5\">**Helper Functions**</font>\n",
    "\n",
    "The functions below will help us plot the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166ea0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images):\n",
    "    png_name = \"{}_{}imgs_{}steps.png\".format(\n",
    "        precision, batch_size, num_steps)\n",
    "    \n",
    "    print(\"Start plotting the generated images to %s\" % (png_name))\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for i in range(len(images)):\n",
    "        ax = plt.subplot(1, len(images), i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af220a7",
   "metadata": {},
   "source": [
    "<font size =\"5\">**Model Loading**</font> <br>\n",
    "First, we construct a model and also define few of the required parameters:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb67cef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 1  # number of iterations in performance measurements\n",
    "use_xla = False  # TF XLA compiler\n",
    "precision = 'fp32'\n",
    "batch_size = 1\n",
    "num_steps = 50  # num of UNET steps in Stable Diffusion\n",
    "seed= 12345  # changing seed will produce different outputs\n",
    "benchmark_result = []\n",
    "\n",
    "model = StableDiffusion(\n",
    "    img_width=512,\n",
    "    img_height=512,\n",
    "    jit_compile=use_xla,   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c260c0",
   "metadata": {},
   "source": [
    "<font size =\"5\">**Running Inference** </font> <br>\n",
    "Next, we give it a prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962f9e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"an astronaut riding a horse on mars\"\n",
    "#prompt = \"people attending intel conference in a big hall with an led screen\" # This is the input for teext2image conversion\n",
    "\n",
    "\n",
    "print(\"Start Warmup\")\n",
    "model.text_to_image(\n",
    "    \"warming up the model\", batch_size=batch_size, num_steps=num_steps\n",
    ") # Warming up the GPU caches before perf measurements\n",
    "# Start inference\n",
    "print(\"Start running inference and generating images\")\n",
    "t = 0\n",
    "for i in range(iterations):\n",
    "    start_time = time.time()\n",
    "    images = model.text_to_image(prompt=prompt, batch_size=batch_size, seed=seed, num_steps=num_steps)\n",
    "    t+=(time.time() - start_time)\n",
    "print(f\"FP32 precision: {(t/iterations):.2f} seconds\")\n",
    "benchmark_result.append([\"FP32 precision\", t/iterations])\n",
    "plot_images(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724c14ad",
   "metadata": {},
   "source": [
    "<font size=\"4\">**Performance computation using AMP FP16 precision** </font>\n",
    "<br>\n",
    "Enable Advanced AMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d776101-e5b8-4a07-aab8-2e6f38a816cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import intel_extension_for_tensorflow as itex\n",
    "print(\"intel_extension_for_tensorflow {}\".format(itex.__version__))\n",
    "\n",
    "auto_mixed_precision_options = itex.AutoMixedPrecisionOptions()\n",
    "auto_mixed_precision_options.data_type = itex.FLOAT16 #Data precision for Advanced Auto mixed Precision\n",
    "\n",
    "graph_options = itex.GraphOptions(auto_mixed_precision_options=auto_mixed_precision_options)\n",
    "graph_options.auto_mixed_precision = itex.ON\n",
    "\n",
    "config = itex.ConfigProto(graph_options=graph_options)\n",
    "itex.set_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b90c7e-80fa-48f5-85c6-a2e9c2c4085e",
   "metadata": {},
   "outputs": [],
   "source": [
    "itex.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f566ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StableDiffusion(\n",
    "    img_width=512,\n",
    "    img_height=512,\n",
    "    jit_compile=use_xla\n",
    ")\n",
    "\n",
    "print(\"Start Warmup\")\n",
    "model.text_to_image(\n",
    "    \"warming up the model\", batch_size=batch_size, num_steps=num_steps\n",
    ")\n",
    "# Start inference\n",
    "print(\"Start running inference and generating images\")\n",
    "t = 0\n",
    "for i in range(iterations):\n",
    "    start_time = time.time()\n",
    "    images = model.text_to_image(prompt=prompt, batch_size=batch_size, seed=seed, num_steps=num_steps)\n",
    "    t+=(time.time() - start_time)\n",
    "    \n",
    "print(f\"AMP FP16 precision: {(t/iterations):.2f} seconds\")\n",
    "benchmark_result.append([\"AMP FP16 precision\", t/iterations])\n",
    "plot_images(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3e0a04-1189-480b-8905-39d600b8b0da",
   "metadata": {},
   "source": [
    "<font size =\"5\">**Performance comparison** <br></font>\n",
    "Lets compare the results wrt inference latency time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0803d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{:<20} {:<20}\".format(\"Model\", \"Runtime\"))\n",
    "for result in benchmark_result:\n",
    "    name, runtime = result\n",
    "    print(\"{:<20} {:<20}\".format(name, runtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a3e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create bar chart with training time results\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.title(\"Stable diffusion Inference on Intel Max GPU\")\n",
    "plt.ylabel(\"Inference Time (seconds)\")\n",
    "plt.bar([\"FP32\", \"FP16-AMP\"], [benchmark_result[0][1], benchmark_result[1][1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d72872-9cfa-4987-ad04-11abdabb0bf5",
   "metadata": {},
   "source": [
    "<font size =\"5\">**Explore Further** <br></font>\n",
    "1. Improve the performance of KerasCV-Stable Diffusion still further by applying advanced optimizations. Refer [ITEX samples](https://github.com/intel/intel-extension-for-tensorflow/tree/main/examples/stable_diffussion_inference)\n",
    "2. Try other interesting stable diffusion prompts and post the image on your social handle. <br> At #Intel #oneapi Devsummit. Ran @StableDiffusion text2image #AI on 4th Gen #intelxeon and Intel Datacenter Max 1100 #GPU  #intelai \n",
    "3. Experiment with other Tensorflow models from Tensorflow-hub on Intel GPU's "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f5ae7c-8382-4967-9c01-73f6b756c77a",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b> Legal Notices and Disclaimers</b></summary>\n",
    "Intel technologies’ features and benefits depend on system configuration and may require enabled hardware, software or service activation. Performance varies depending on system configuration. No computer system can be absolutely secure. Check with your system manufacturer or retailer or learn more at www.intel.com.<br>\n",
    "Cost reduction scenarios described including recommendations are intended as examples of how a given Intel-based product, in the specified circumstances and configurations, may affect future costs and provide cost savings. Circumstances will vary. Intel does not guarantee any costs or cost reduction.<br>\n",
    "This document contains information on products, services and/or processes in development. All information provided here is subject to change without notice. Contact your Intel representative to obtain the latest forecast, schedule, specifications and roadmaps. <br>\n",
    "Any forecasts of goods and services needed for Intel’s operations are provided for discussion purposes only. Intel will have no liability to make any purchase in connection with forecasts published in this document.<br>\n",
    "Intel technologies may require enabled hardware, software or service activation.<br>\n",
    "Software and workloads used in performance tests may have been optimized for performance only on Intel microprocessors.  <br>\n",
    "Performance tests, are measured using specific computer systems, components, software, operations and functions.  Any change to any of those factors may cause the results to vary.  You should consult other information and performance tests to assist you in fully evaluating your contemplated purchases, including the performance of that product when combined with other products.   For more complete information visit www.intel.com/benchmarks.<br>\n",
    "\n",
    "|* Other names and brands may be claimed as the property of others. <br>\n",
    "\n",
    "Your costs and results may vary. <br>\n",
    "© Intel Corporation.  Intel, the Intel logo, and other Intel marks are trademarks of Intel Corporation or its subsidiaries.  Other names and brands may be claimed as the property of others.<br>\n",
    "Copyright 2023 Intel Corporation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "itex_xpu",
   "language": "python",
   "name": "itex_xpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
